+++
title = "Thesis"
author = ["Sunny Rahul"]
draft = false
+++

## <span class="org-todo todo TODO">TODO</span> Presentation to Prof Klakow Next Week {#presentation-to-prof-klakow-next-week}


## <span class="org-todo todo TODO">TODO</span> Do Literature Review of NER task w.r.t Active Learning {#do-literature-review-of-ner-task-w-dot-r-dot-t-active-learning}


## Prompt {#prompt}

Labeled datasets in the ATC domain are rare, which makes training a neural network challenging. One way to overcome this is to automatically annotate data, e.g. rule-based. This results in erroneous, so called noisy labels, which can then be used in semi-supervised learning together with a small amount of costly hand labeled data. Another way to get decent training data for a DNN is to annotate only the data, that has the highest impact on the model performance. This can be done via active learning.

For thesis, we want to look into methods for combining active learning and noisy labels:
    Reannotation of noisy labels during the active learning loop
    Trade-off between reannotation and new annotation
    Determining the optimal sequence (of datapoints to label/relabel) for the active learning loop in the ATC task
    Analysis of the optimal sequence and extraction of its properties
    Finding ways to approach the optimal sequence for new datasets
